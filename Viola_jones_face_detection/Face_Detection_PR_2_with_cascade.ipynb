{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5kB0dsu1RDpY"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import os\n",
    "import tarfile\n",
    "import shutil\n",
    "import hashlib\n",
    "import glob\n",
    "import random\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from typing import *\n",
    "\n",
    "from numba import jit\n",
    "import requests\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "w6kUgpYZBSiI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VsOpK31HS1MS"
   },
   "outputs": [],
   "source": [
    "dataset_path = 'dataset'\n",
    "\n",
    "results_path = 'results'\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    os.mkdir(dataset_path)\n",
    "\n",
    "if not os.path.exists(results_path):\n",
    "    os.mkdir(results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "s_4GPhspTlZ-"
   },
   "outputs": [],
   "source": [
    "def download_file(url: str, path: str):\n",
    "    print('Downloading file ...')\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(path, 'wb') as f:\n",
    "            r.raw.decode_content = True\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "    print('Downloading completed.')\n",
    "    \n",
    "\n",
    "\n",
    "def untar(file_path: str, dest_path: str):\n",
    "    print('Extracting file.')\n",
    "    with tarfile.open(file_path, 'r:gz') as f:\n",
    "        f.extractall(dest_path)\n",
    "    print('Extraction completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jFF1UIo6Tw8C",
    "outputId": "5d680584-0180-4f1c-c375-b1371dff0311"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading file ...\n",
      "Downloading completed.\n"
     ]
    }
   ],
   "source": [
    "faces_url = 'https://www.dropbox.com/s/ubjjoo0b2wz4vgz/faces_aligned_small_mirrored_co_aligned_cropped_cleaned.tar.gz?dl=1'\n",
    "\n",
    "\n",
    "faces_archive = os.path.join(dataset_path, 'faces_aligned_small_mirrored_co_aligned_cropped_cleaned.tar.gz')\n",
    "faces_dir = os.path.join(dataset_path, 'faces_aligned_small_mirrored_co_aligned_cropped_cleaned')\n",
    "\n",
    "if not os.path.exists(faces_archive):\n",
    "    download_file(faces_url, faces_archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ewUr3TDkUAy0",
    "outputId": "eae9f6af-aef6-437f-fef8-d114da91c5da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting file.\n",
      "Extraction completed.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(faces_dir):\n",
    "    untar(faces_archive, dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xg20Vko2UL7y",
    "outputId": "018904fc-0094-42ec-b261-aae619190d26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37921\n"
     ]
    }
   ],
   "source": [
    "face_image_files = glob.glob(os.path.join(faces_dir, '**', '*.png'), recursive=True)\n",
    "print(len(face_image_files))\n",
    "\n",
    "#Taking 2000 face images as our total number training and testing dataset images\n",
    "face_image_files=face_image_files[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yKiPXT5TVuL5"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Image_SIZE=22\n",
    "\n",
    "def to_float_array(img: Image.Image) -> np.ndarray:\n",
    "    return np.array(img).astype(np.float32) / 255.\n",
    "\n",
    "def to_image_func(values: np.ndarray) -> Image.Image:\n",
    "    return Image.fromarray(np.uint8(values * 255.))\n",
    "\n",
    "def gamma_func(values: np.ndarray, coeff: float=2.2) -> np.ndarray:\n",
    "    return values**(1./coeff)\n",
    "\n",
    "def open_face(path: str, resize: bool=True) -> Image.Image:\n",
    "    CROP= 50\n",
    "    img = Image.open(path)\n",
    "    img = to_image_func(gamma_func(to_float_array(img)[CROP:, :]))\n",
    "    min_size = np.min(img.size)\n",
    "    img = ImageOps.fit(img, (min_size, min_size), Image.ANTIALIAS)\n",
    "    if resize:\n",
    "        img = img.resize((Image_SIZE, Image_SIZE), Image.ANTIALIAS)\n",
    "    return img.convert('L')\n",
    "\n",
    "def gleam_func(values: np.ndarray) -> np.ndarray:\n",
    "    return np.sum(gamma_func(values), axis=2) / values.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "i4kw0NKFjSJ8"
   },
   "outputs": [],
   "source": [
    "\n",
    "face_images = [open_face(f) for f in face_image_files]\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-sn4PKiDqPbO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gkaHLy0RjSms"
   },
   "outputs": [],
   "source": [
    "def getImages(all_images):\n",
    "    images, nimages = [], []\n",
    "\n",
    "    for im in all_images:\n",
    "        images.append(im)\n",
    "\n",
    "        img = normalize_image(im)\n",
    "        nimages.append(im)\n",
    "\n",
    "    images = np.stack(images, axis=0)\n",
    "    nimages = np.stack(nimages, axis=0)\n",
    "\n",
    "    return images, nimages\n",
    "\n",
    "\n",
    "def normalize_image(img):\n",
    "    img = np.array(img)\n",
    "    mean = img.mean()\n",
    "    std = img.std()\n",
    "    \n",
    "    img = (img - mean) / std \n",
    "    img = np.ndarray.tolist(img)\n",
    "    return img\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149
    },
    "id": "1MpSfHXnnJwC",
    "outputId": "753e6860-7cbd-4d63-8c4b-3a0a5acb0a73"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABYAAAAWCAAAAADh3zPnAAABz0lEQVR4nAXBy2oTURgA4P8/52SunbSTy2SGmFqsGHBlvSCCSxFBN4rSjS/g07j2EVzY7hRXLsTLonipVUQs1iQaIp1kLulkLjnn9/vQN7Ra5rShuvuIkarCt09+1JoPhW7p3shRm9vXuEJkaxfWv0G6L7SWn3k327e6pQRSUAtuH4x5IRQT0yv3fJYIRsgY4fW93XopqnQ0s6LCWwFSMl0SMy+/6IBQUZSP9krn0oYoJ0NmGcFpL5gwVcDWVd9dfB+TMryCPL1xLgHWNPoP5GBQp78gMD4E0FFVmjBFx+l19drXgrjTv2iWhPPqSHjlGviOUMgJmYMV4ckwjYW3uVJIxoqKJEglEIhYtME+fZ4W2RLUCQEspVK0lFz3xZkPSRC6YiaVVLkmUS7TqdJZH6IkDKcxDwcJN1CWUBZoiIHKEvcfE73Gqs0qBKUPi/UbYnv4+7A1X/C5znMpbQ3m7fs/nyN9eSdRBO6x1TFMi6oqmW1NCBUCvH/dbTVt09BQZpH7snMnYyQreQpn8cKwdUSV2+7Zp2POABlvW/E0TBa5WsRG3VT7j0kAg6OPWi0t01Vy665t4hvaWQj482onPB84ZnLcaze4bh78qufP/gPvuee4gvRWMAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=22x22 at 0x7F569CE32150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABYAAAAWCAAAAADh3zPnAAABnklEQVR4nAXB2WoTURgA4H+b7SRpzB6TkBJBBEGKXqWv4ZP5Fj6CD6AIxRtBLxStSpvGGCbNMs0yc+b8x+/DN+Pl+aAaknJM4Epri2ymbfkzq2X7FwaYwCMTh+Ue3U625bYZtLgihITgkCxY2JN6bA/y1HpkZiSi0+LEJFaGg8edqiFiJHEHm817SOIG/bvFMDJPOwiH61WrUjeAKBiWRbgM3P3FuWbFkWraDxxJBPEIRKebdBS0ar6XuO4Dq4wh7IbPTNK7VQIzdW7/yBWltFI77AgX1nvv0XqvwITUgs2aBKjYgPceQW3OTHSnxW1aet4cQ/bqVAsQEXoJsL45uOzv6mb2AKpWhYVpUi9xk2b3YXhTxuTVKXMgwpUUBNe2MW5GahWsZ08snzXMbWB+lF2XUJHgQRSA6OosKv/9Di6eGOHwjFNiYkL6susb+/Nb0WgaQdhSjERIpB8b7br9uoAkiSXHKiACEvH83chU8qvro4cyahACIIJg8il6/f2we/+rbU6z55PkZAlREMyH3jRf2fly0n+bXV6+ih3if44SyHJBu86vAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=22x22 at 0x7F569CE2CF50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABYAAAAWCAAAAADh3zPnAAABjklEQVR4nAXBS2/TQBQG0O/emfEjL0xxm5Y2RRUSbJBQF/wh/iBIrJBYsmLBBsS2EmoUpS2ExLU9nhnfyzn0/ujqzWvHCiSlOHTN+qaXYK/MflmAQUqqpOP4hLrS27W/nisUKoCOo4rjh8nBtrOaxZACUCFjlNNmYWwdyiKqsVCFdo0f0P3tX9rZ3dCtO8mWz7T9vbUU59NijPZ882es0y6EZPb+rCmcXFTxub0cphPfjvmC1JdLH3RxWq+u6Us1PWIlBcsNn7nYxf3Pk3NLfJzYqAqUJEJJ+ZVxbNqWVJWgoDSqYBQ3c2ykJ4CgMIUmhSTNcmY2h0YBQCSkEZCE0jKzTY0o1NhAUxZNqcjAFjAxOBCoOO2hKQkRyBJYhglCL6nrp099UgshS0xMyTqM3ma5RE/JGVgmE30VMjNEyk3fxfLuW1VbwN2HFy077PI59y2G8ld7YFj+3k74X8hKx/4+0CrfVZXNhq+3+bvlZpsadY+xWpUfHxYlbz/8mN1+louT0Ps+O76sPzVvH+U/1aLlv39tHGoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=22x22 at 0x7F569AC87C50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABYAAAAWCAAAAADh3zPnAAABoElEQVR4nAXBy47TMBQA0Hvtaztp4qRNacsAFdIsEdJsZssX8Kn8ByxASKx4M0WidJiWTsg7dmxzDr56fd4WNH+wqPqusnXVhaZKXpJ3osjk8knu5cWxZoJqKcaGfNDJYh7HLG9lHmCpf018shR4Nq1yJXnGbar0IAdTOUYQqVXikHOO1o8GxeJeDYp0pNbd7HzKUt8fyyzulHappvSxS5yDbiJ2+2elyonnUWFY9DyN6sN3UiDMen7TVDIvNj2xeMMfehYY8ZjPnrWG6lnQNGRbl1IIE3jlgp5NTZVTzJzhCEyQDyicIInexoVi2AcXIAygZKwacN5YmSjitqQRbfBnPDiUNNRTrJEQTUATcmcHZGmLbSvW5IlhADdhE6Vx1I1lFpwSHggQA0TQtAr6vhSzHhIAJAYACEp1QigGqhtbvTETscD554s1YcPHe86Gk353d5kSivbrt81fnWDnMirv/m2/vPlYkNx/aAJd7iifT/3xWBePTBhu6P0PUPbwQh/OzJxu+9X1fqe8YJ8M82L3Uz9dlvvfXXE1f2u59f8BsE7WMIuP2K4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=22x22 at 0x7F569C712ED0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABYAAAAWCAAAAADh3zPnAAABqElEQVR4nAXBXW/SUBgA4PO+5z09LV0LZZBhWGaiWZxeGmP8A/5K/4i3euPNMEYu1ClxWYgyulIQaHu+fR54p9nrMSdCxpyzpq2XsxenGtH3E+AcARgCIAGYEgPyEHGGEFgIgQED36nKB+IIFgULHhhD5AG0PCpGDIltdnnGPDD4u7i3KmgMlCg81m2bXRYe7mbZ2a6E3j5QMdrKi7i5X8moXl2KvTdRs3xO2XCzyHfrYloOb0ldG5kt8Mk5ZRLqpydZmnRSnzxOO29tNdZ0yJ5NqCioldHI235qah2Hf7R9hH2OBEQuN8Qt7h8GxlPToJOCQDvRuYRaXvCINFnVOyTBi3KRfhwnk6A37NQQsbs0Nhzs4Kp6M+wpu/3duwJLzFSDlDMnRa6c3dk/9ZnQjAA/TaeaHQ7eNB5HTcXH3noSs8/lq4HhicOIcar3Mjm4gDczsfyqncxiimLeKsWjRmn6ZYSPt3kS8oHrunZbdv1zZ5EoUJ7f1bEAoHDz5Vi+//AQ6EKt29uX7Xw58bb68c2i8z9XE5q26ff524meX7eqUyHSmqRZ/wdwNOncZcjCMwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=22x22 at 0x7F569AB87CD0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABYAAAAWCAAAAADh3zPnAAABmElEQVR4nAXBvW4TQRAA4JnZ2dvz710c4tg4MhZBgEhDT0FFT8Hb8QK0PAEFokY0qRIlCIRCjC3H5/vb253h+/DjF/PizSTtERkEVIi/f3x7+4FcQxMPBAgAoiDmpIi10MWopaozgCiKABjG4/0MOUNFASIARAKUiEPzRGlxIcLNzlurMZT7RiA9P/P812Tw8+bo4fh13l7tznJnpu+3KX1vlpouhsmvS7B9uq9IHq26wM1q7fpreR7v6/xxvJ0Zw/WQ+eS6Z/NnU3f30EGyfGnVsyjRqHFgh+pbIKCetAHRGqDEegMSY+0xRiEEECWg6VhAhLTgFFEENMRITOmr42FR1QdfbPYeo4oQG6KwfDcvq7I04fJPYAIAZlXWQKc3jYN8Nh3ZACKRFJQVQ5YV/fU6K0bsBokEZ0TJoMCqPLh9k5CSBs8MqqSifn6+sctuuzG56yQhNMiKiPr0qjqdcZZz2w0SQkwZSTW4o3/jxcTGtmTL2v+8ZURQ7U/Wd5UZjMmlluz11x2DKrjb6LAm6mW9hMzhUzP/D8AvzVOtF5EKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=22x22 at 0x7F569CE37910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# faces, nfaces = getImages(face_images)\n",
    "face_images_copy=face_images.copy()\n",
    "\n",
    "def display_five(face_images_copy):\n",
    "  k=1\n",
    "\n",
    "  for i,img in enumerate(face_images_copy):\n",
    "    display(img)\n",
    "    if i==5:\n",
    "      break\n",
    "\n",
    "random.seed(10)\n",
    "# display_five(face_images_copy)\n",
    "random.shuffle(face_images_copy)\n",
    "\n",
    "\n",
    "# print (\"   \")\n",
    "# print (\"   \")\n",
    "display_five(face_images_copy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "eerJbFntRXRu"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_faces=face_images_copy[:int(.8*len(face_images_copy))]\n",
    "test_faces=face_images_copy[int(.8*len(face_images_copy)):]\n",
    "\n",
    "# print (len(train_faces))\n",
    "# print (len(test_faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rKq2t89qRfFX",
    "outputId": "dda2a6d4-de78-4914-ce8b-7acfacde7746"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading file ...\n",
      "Downloading completed.\n"
     ]
    }
   ],
   "source": [
    "backgrounds_url = 'http://dags.stanford.edu/data/iccv09Data.tar.gz'\n",
    "\n",
    "\n",
    "backgrounds_archive = os.path.join(dataset_path, 'iccv09Data.tar.gz')\n",
    "backgrounds_dir = os.path.join(dataset_path, 'iccv09Data')\n",
    "\n",
    "if not os.path.exists(backgrounds_archive):\n",
    "    download_file(backgrounds_url, backgrounds_archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g3DK2JNPRmn3",
    "outputId": "7d024d09-018f-4d61-cf39-0911a9f0b998"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting file.\n",
      "Extraction completed.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(backgrounds_dir):\n",
    "    untar(backgrounds_archive, dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lmQhY9ekRpUa",
    "outputId": "23dc1cc0-11d3-415f-d5d6-764c2a1c5fae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "715"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background_image_files = glob.glob(os.path.join(backgrounds_dir, '**', '*.jpg'), recursive=True)\n",
    "len(background_image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "y_7W8dkIRsWO"
   },
   "outputs": [],
   "source": [
    "Image_SIZE_2=40\n",
    "Image_SIZE_1=22\n",
    "\n",
    "def random_crop(img: Image.Image) -> Image.Image:\n",
    "    max_allowed_size = np.min(img.size)\n",
    "    size = random.randint(Image_SIZE_2, max_allowed_size)\n",
    "    max_width = img.size[0] - size - 1\n",
    "    max_height = img.size[1] - size - 1\n",
    "    left = 0 if (max_width <= 1)  else random.randint(0, max_width)\n",
    "    top  = 0 if (max_height <= 1) else random.randint(0, max_height)\n",
    "    return img.crop((left,top,left+size,top+size))\n",
    "\n",
    "def open_background(path: str, resize: bool=True) -> Image.Image:\n",
    "    img = Image.open(path)\n",
    "    img = to_image_func(gleam_func(to_float_array(img)))\n",
    "    img = random_crop(img)\n",
    "    if resize:\n",
    "        img = img.resize((Image_SIZE_1, Image_SIZE_1), Image.ANTIALIAS)\n",
    "    return img.convert('L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "tw__8kBYS2ML"
   },
   "outputs": [],
   "source": [
    "# background_images=[]\n",
    "\n",
    "# for i in range(8):\n",
    "#   background_images=background_images+[open_background(f) for f in background_image_files]\n",
    "\n",
    "\n",
    "background_images_1 = [open_background(f) for f in background_image_files]\n",
    "background_images_2 = [open_background(f) for f in background_image_files]\n",
    "# background_images_3 = [open_background(f) for f in background_image_files]\n",
    "# background_images_4 = [open_background(f) for f in background_image_files]\n",
    "# background_images_5 = [open_background(f) for f in background_image_files]\n",
    "# background_images_6 = [open_background(f) for f in background_image_files]\n",
    "# background_images_7 = [open_background(f) for f in background_image_files]\n",
    "# background_images_8 = [open_background(f) for f in background_image_files]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UhGG63zBTNZ3",
    "outputId": "5a10dce4-1b1c-4f9a-be06-72c2c021826a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1430"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# background_images=background_images_1+background_images_2+background_images_3+background_images_4+\\\n",
    "# background_images_5+background_images_6+background_images_7+background_images_8\n",
    "\n",
    "background_images=background_images_1+background_images_2\n",
    "\n",
    "len(background_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149
    },
    "id": "0yQO27lFVFzu",
    "outputId": "48cb09ae-f90e-4bea-dfd4-9dbc03f7be0b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABYAAAAWCAAAAADh3zPnAAABkElEQVR4nAXBSW4TQRQA0P9//eoh1e0hJsgEiYAiNiwsFpyA83BBrgEIRUjIwAIUGrvt6sE1F+/hhzpwt/GgS/W5GbfzlMLbU6Kcdu+bs9jtorhTT1XtbK1/dOzX2gZmY7hVmvNVX8eTTQTN8aet1eEPKZvs3ROfrNgWVAkUHPxsKFl3wIXKLJ+vaMbjlxDd4QTBm+kMNxKpCCwnflPLqW3beH1Jg7w5D8XDyDK8XPiQtLarF7yBRxayx5Lz/H0hnhX1t9r4LQQntuIYHDe3+19xCJ1t91/f3aZNXxp1krwPa1O8GtbZ3/PxdqiW/eu/EPGjJiqXVPqY3UG3tJLHJjh8QJeFWgq042VKV+BTrhhYl4Jw1ojIRRVJBGTHkRUCIBQAkD1QNFHJKiZGBBAkiAmBynwejSnzI2cuhc2haKo0TZcUZQrdSfPF82JBzg2dnmmt/NDPxC3+jv96uMa8LpDGVCnpR2MNJjicOisrycQh5JxJIAj8JJzIGRIICkAAQACAbAFjRgAMmSACYEYE+A8xIOKue+TCAwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=22x22 at 0x7F569C3EC7D0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABYAAAAWCAAAAADh3zPnAAABnklEQVR4nAXByW4TQRAA0Krq6llsj21kQha2CCS4IuDCiX/lFzhyjgQ+cOGSEAhBlpXEMZ7x2LP0Vs17+CkTUqT09OSBqZBESUQKbCTxTELtGibjPbAggIucNj7xBKFRA544AxEQOHIaO8ggBqmxcNUgBtBInkPqepsrz1Ivt+XxgSYKFhnsLHOZrtsuPbf6psonRZYEDnL0uFe6v+zXTret5jIfTwomSAjR8ivZXdxp7DSYelXQII9aHCCr2fvX0WB0xrQbRuxE+QCBJXv74nJlE4WRGLjrsh5BAnvI3yy+3SN+PGSEbnHKMSYCJOTq8pYgTjkiNLV2ufbbMDLLeTXdkWlYULXlkxiz88/jl39+qYF7uD+Yc/RGqYyDsR3O9+NBC/jsakOVSRX1Jtpc70XLu4FtDk96GibNLlG2l9IxmfZOe3N19IG8LwpT9dp+92RBrh1Q+WVNw7FvZ5Ol/rnwKKSfbiE2t1/J72MBF+v7HyKdgqIeklXbU+pUGs/Wj35XJoDioRynUfp/xAkuz/5u9PORFzOiZpVZ66//A3lh9dDg4jIQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=22x22 at 0x7F569BD83E10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABYAAAAWCAAAAADh3zPnAAABd0lEQVR4nAXBTW7UQBAG0Pqqy257EBMl0SAhdtnwt2DPOThKrsJ5WLOCFVIWSYSEolFImHgm9rRdXVW8hzswYpnJPBECDOfgkMIEqhbmSkhO5KBUhUGExM4WoGCKRBFJIkBOQRxmCPJqbnORe6IKVA8zNfJYVE1V/hI5QLDwcI0UnGvjonAYgloi9U27LexGJkZENVVuOXm7HgihxCxhTGRyPpfnLj8eVTRHDTEP4ZquVsv1Z+XT7SMaA4QbFCd/+HB78+59zqvjOueWZXM4nM0v+uPbV9PFCdXXbsuzFnz93l6uNRUdfSrQ6hGhi+jHL+1+Gcuiziy5c1XlHj/7vANqOIGWcpxnC1CFTbWJ++Fm8GHuswMQUMW/TNP++erbn+l2d3LxaS3FukyybWK5ux7O8/By9/R7eHNWaLMK/Ho6jA/LtFfTWo7j0va9IMmP0abKzqA2S39q5ty1SWb3xNalcQalsAA8SRI0QtFwdGHw1BZLnIT+AxYZ+8KEI7LiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=22x22 at 0x7F569CA2A390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABYAAAAWCAAAAADh3zPnAAAA+ElEQVR4nD2QS45TQRAEs/qVPRq84/4X4HAgITSMx68rgoUtchnKj5T1wyJJEZLUxUeZ6qssxBGrrsd91OoktYyLCro3O6ZFFJNK+UhAbQBFgiZRgR5nFFVHE8bQYRAQlYmCduIw4yhCgmj/XWbOYUCNUbUfJLLZoilJQpq9TRUzWuYpe/YArCoreXLSMoOYlYlPbjqls9bsLhNfNQ3HxJ1MzMtO1mXuWbN6yf9B7W/M59zOM5rSV2Rd327vx2+OeRY/z7H7er6teqzL7FQmkVquWkev9xuf2xqiqYzr4wuLdev7AiEK6V/kPPkz+fj5/bpPar6O4/4P8HYfXhzfSDUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=22x22 at 0x7F569C3FB990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABYAAAAWCAAAAADh3zPnAAABpUlEQVR4nAXByY7TQBAA0Kp2eYntxFknhCgKYe5IwAHxC/wqdz5gDjAHkDjACSREMsMoibM48drtquY9/LL04pJa+2l63A1xn0TxgdmSUzwE6kXvvtmcomtVmsvbHywNgYsjD/798U+HlHWzv339NepcSCp0ITDJo6s5H3gvY//VeuArBWzRjnL0O8oTfMqaFDQTC1ij0mOyNWxkxh3qhmNFOqs2yg8XP9PGYhJuA7lxAkuhyO78PTLHqxT9+TMeag+VQxrzs5TGnU8qfTNsoKsCdkpStsxgIFzqngweikO07HNBiqluGZQXh8vVaT7Nf+vGhhPSbr84zUypEmsWzexDWtyNe0odi2a36uT19pjt9ub2zVGeLuuKHveCvL603Hc4Dj4nq3ycdf/ix62/oI7OwPXKmK9hXrr9b3f0DhlFAH1ibmrgTAXj+5xyAED0eiSejaWykzbN3me4QQQEsUFgQay10F529ZmeAC2IRQ6jVlkSBpyeDP1ClLYVxwd3xIBg6opNS2flICoXrKPqrsMGe7F1FSUeIdjW6JLb52HN6IA4/n/6w/nDZ1m3RgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=22x22 at 0x7F569B7C54D0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABYAAAAWCAAAAADh3zPnAAABiklEQVR4nCXMzW7TQBQF4HNn7tj5w42aJiGoSAUB4mfDAom3Z8UWFoAqFiCqtBW0TpqGOo3tGd/Dgu8BPvk+OP9y8LAoMzneXJ8sfnbHKQ+t25d8H9PR4CbbXK3l9+T5sMgNmj5NvE6GjNMP+zfBrctxbDOny/HkBk3W5Do7eDSgC9koZbnqVJrLxe007t9FrpacDS0tWyf9/T6z3XDexeu2/HtUWNlcVYrdOC1c+SRcHs7vK/rQO6vmXqs6ve1bf1n1euPPZ8ObmXtRe9E/+Vrazmv99Ku7ncxuP0K1M52mX21R+0OJYP7s6seh2CAb6Ym9tCSW6CBoyyLEVG9VE+9AAUB0xUXDuHMNLjQCBM0Ac3HVT5YjEEqQBlLEiq30KqgIvXaEQSig5Q8K5iAN92owAADpq5VIgLfUjbQTCAgDZNWE1HHF4ERFSBCExNPt4ynjJsJTYQBBwLU1zr2Pr16321b5/yboRHelpmnAolESAACxfrHJm4bfTiVQITAIBOH6znsxMrK++wekp+XuNbRgHQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=22x22 at 0x7F569BD8BE10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "background_images_copy=background_images.copy()\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "random.shuffle(background_images_copy)\n",
    "display_five(background_images_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "3GuSJe7WV4a7"
   },
   "outputs": [],
   "source": [
    "train_non_faces=background_images_copy[:int(.8*len(background_images_copy))]\n",
    "test_non_faces=background_images_copy[int(.8*len(background_images_copy)):]\n",
    "\n",
    "# print (len(train_non_faces))\n",
    "# print (len(test_non_faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c4tWa2n_WJWE",
    "outputId": "8b4876a3-800e-472d-b623-734935d8d4cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of faces in training data:  1600\n",
      "Number of non faces in training data:  1144\n"
     ]
    }
   ],
   "source": [
    "faces, nfaces = getImages(train_faces)\n",
    "\n",
    "print(\"Number of faces in training data: \", len(faces))\n",
    "nonfaces, nnonfaces = getImages(train_non_faces)\n",
    "print(\"Number of non faces in training data: \", len(nonfaces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j_mm6d3pYrIT",
    "outputId": "86505d21-59ec-4b0e-c9ba-c585daaa7dce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of faces in test data:  400\n",
      "Number of non faces in test data:  286\n"
     ]
    }
   ],
   "source": [
    "_, testfaces = getImages(test_faces)\n",
    "print(\"Number of faces in test data: \", len(testfaces))\n",
    "\n",
    "_, testnonfaces = getImages(test_non_faces)\n",
    "print(\"Number of non faces in test data: \", len(testnonfaces))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "KllYDPAdY5O0"
   },
   "outputs": [],
   "source": [
    "data = np.array(nfaces.tolist()+ nnonfaces.tolist())\n",
    "y = [1] * len(nfaces) + [0] * len(nnonfaces)\n",
    "\n",
    "# random shuffle the data\n",
    "trainingData = list(zip(data, y))\n",
    "random.seed(10)\n",
    "random.shuffle(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Nr1agJHbZLDv"
   },
   "outputs": [],
   "source": [
    "test_data = np.array(testfaces.tolist() + testnonfaces.tolist())\n",
    "test_y = [1] * len(testfaces) + [0] * len(testnonfaces)\n",
    "testData = list(zip(test_data, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "I1IFumv8_ZLX"
   },
   "outputs": [],
   "source": [
    "class Integral_Image:\n",
    "    def __init__(self, image):\n",
    "        self.image = image\n",
    "        self.integral = self.create_integral_image(self.image)\n",
    "\n",
    "\n",
    "    def create_integral_image(self, image):\n",
    "        temp=np.cumsum(image, axis=0)\n",
    "        integral_image = np.cumsum(temp, axis=1)\n",
    "        integral_image=np.pad(integral_image, (1, 1), 'constant', constant_values=(0, 0))\n",
    "        return integral_image[:-1, :-1]\n",
    "\n",
    "    def compute_integral_area(self, Coordinates):\n",
    "        positive_area=self.integral[Coordinates[0][0]][Coordinates[0][1]]  + self.integral[Coordinates[2][0]][Coordinates[2][1]] \n",
    "        negative_area= self.integral[Coordinates[1][0]][Coordinates[1][1]] + self.integral[Coordinates[3][0]][Coordinates[3][1]]\n",
    "        integral_area=positive_area-negative_area\n",
    "        return integral_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "1gVlfdvFY4Q1"
   },
   "outputs": [],
   "source": [
    "\n",
    "Haar_features={}\n",
    "\n",
    "Haar_features['Vertical_2_rectangle']=(1, 2)\n",
    "Haar_features['Horizontal_2_rectangle']=(2,1)\n",
    "Haar_features['Vertical_3_rectangle']=(3,1)\n",
    "Haar_features['Horizontal_3_rectangle']=(1,3)\n",
    "Haar_features['4_rectangles']=(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "rrMi_LRfVEEG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "scmkdffPotzF"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Viola_Jones:\n",
    "    def __init__(self, rounds=10):\n",
    "        self.rounds = rounds\n",
    "        self.classifiers = []\n",
    "        self.alphas = []\n",
    "   \n",
    "\n",
    "    def create_Haar_features(self, size_of_window):\n",
    "        features = []\n",
    "\n",
    "        for feature_type in Haar_features.keys():\n",
    "            temp_features = []\n",
    "            feature=Haar_features[feature_type]\n",
    "            for width in range(feature[0], size_of_window + 1, feature[0]):\n",
    "                for height in range(feature[1], size_of_window + 1, feature[1]):\n",
    "                    for x in range(0, size_of_window - width + 1):\n",
    "                        for y in range(0, size_of_window - height + 1):\n",
    "                            temp_features.append(Rectangular_Region(x, y, width, height, feature))\n",
    "            print (\"\\n\")\n",
    "            print(\"Total features of type {} : {}\".format(str(feature_type), len(temp_features)))\n",
    "            features += temp_features\n",
    "        print (\"\\n\")\n",
    "        print(\"Total calculated features: {}\".format(len(features)))\n",
    "        \n",
    "        return np.array(features)\n",
    "\n",
    "\n",
    "\n",
    "    def train(self, trainingData):\n",
    "        data, y = zip(*trainingData)\n",
    "        number_of_faces = np.sum(y) \n",
    "\n",
    "        number_of_nonfaces =len(y) - np.sum(y)\n",
    "\n",
    "        weights = np.zeros(len(y), dtype=np.float32)\n",
    "        weights[np.array(y) == 1] = 1. / (2. * number_of_faces)\n",
    "        weights[np.array(y) == 0] = 1. / (2. * number_of_nonfaces)\n",
    "\n",
    "        print (\"\\n\")\n",
    "        print(\"Creating the integral images..\")\n",
    "        \n",
    "        Integral_Images = list(map(lambda x: Integral_Image(x), data))\n",
    "        print (\"\\n\")\n",
    "        print(\"Creating the integral images done\")\n",
    "        print (\"\\n\")\n",
    "        print(\"Creating the Haar features\")\n",
    "        print (\"\\n\")\n",
    "        features = self.create_Haar_features(data[0].shape[0])\n",
    "        \n",
    "        print(\"Applying the created Haar features\")\n",
    "        print (\"\\n\")\n",
    "        X = np.zeros((len(features), len(Integral_Images)))\n",
    "        for i in tqdm(range(len(features))):\n",
    "            X[i] = list(map(lambda x: features[i].computeFeature(x), Integral_Images))\n",
    "\n",
    "\n",
    "        indices = SelectPercentile(f_classif, percentile=10).fit(X.T, y).get_support(indices=True)\n",
    "        X = X[indices]\n",
    "        features = features[indices]\n",
    "\n",
    "        for t in range(self.rounds):\n",
    "            print (\"\\n\")\n",
    "            print(\"Training Weak Classifier Round number: \" + str(t + 1))\n",
    "            weights = weights / np.sum(weights)\n",
    "        \n",
    "\n",
    "            positive_total = np.sum(weights[np.where(y == 1)])\n",
    "            negative_total = np.sum(weights[np.where(y == 0)])\n",
    "\n",
    "            weak_classifiers = []\n",
    "            for index, feature in enumerate(X):\n",
    "                applied_feature = sorted(zip(weights, feature, y), key=lambda x: x[1])\n",
    "\n",
    "                seen_positive, seen_negative = 0, 0\n",
    "                positive_weights, negative_weights = 0, 0\n",
    "                minimum_error, best_feature, best_threshold, best_polarity = float('inf'), None, None, None\n",
    "                for w, f, label in applied_feature:\n",
    "                    error = min(negative_weights + positive_total - positive_weights,\n",
    "                                positive_weights + negative_total - negative_weights)\n",
    "\n",
    "                    if error < minimum_error:\n",
    "                        minimum_error = error\n",
    "                        best_feature = features[index]\n",
    "                        best_threshold = f\n",
    "                        best_polarity = 1 if seen_positive > seen_negative else -1\n",
    "\n",
    "                    if label == 1:\n",
    "                        seen_positive += 1\n",
    "                        positive_weights += w\n",
    "                    else:\n",
    "                        seen_negative += 1\n",
    "                        negative_weights += w\n",
    "                    \n",
    "                classifier = Classifier(best_feature, best_threshold, best_polarity)\n",
    "                weak_classifiers.append(classifier)\n",
    "\n",
    "\n",
    "            best_classifier, best_error, best_accuracy = None, float('inf'), None\n",
    "            for classifier in tqdm(weak_classifiers):\n",
    "                error, accuracy = 0, []\n",
    "                for data, label, w in zip(Integral_Images, y, weights):\n",
    "                    classify = classifier.classify(data)\n",
    "                    correctness = np.abs(classify - label)\n",
    "                    accuracy.append(correctness)\n",
    "                    error += w * correctness\n",
    "                    \n",
    "                error = error / len(Integral_Images)\n",
    "                \n",
    "                if error < best_error:\n",
    "                    best_classifier, best_error, best_accuracy = classifier, error, accuracy\n",
    "\n",
    "\n",
    "            classifier, error, accuracy = best_classifier, best_error, best_accuracy\n",
    "        \n",
    "            beta = error / (1.0 - error)\n",
    "            for i in range(len(accuracy)):\n",
    "                weights[i] = weights[i] * math.pow(beta, 1 - accuracy[i])\n",
    "\n",
    "            alpha = np.log(1.0 / (beta + 1e-18))\n",
    "            self.alphas.append(alpha)\n",
    "            self.classifiers.append(classifier)\n",
    "       \n",
    "            print(\"{}, \\nerror: {}, \\nalpha: {}\".format(classifier, error, alpha))\n",
    "\n",
    "        return self.classifiers, self.alphas\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def classify(self, image, alphas=None, classifiers=None, threshold=0.5):\n",
    "        total = 0\n",
    "       \n",
    "        if alphas is None and classifiers is None:\n",
    "            alphas = self.alphas\n",
    "            classifiers = self.classifiers\n",
    "\n",
    "        for alpha, classifier in zip(alphas, classifiers):\n",
    "            classify = classifier.classify(image)\n",
    "            total += alpha * classify\n",
    "\n",
    "        return 1 if total >= threshold * sum(alphas) else 0\n",
    "\n",
    "\n",
    "    def evaluate(self, data, rounds, threshold=0.5, print_details=False):\n",
    "        X, y = zip(*data)\n",
    "        Integral_Images = list(map(lambda x: Integral_Image(x), X))\n",
    "        \n",
    "        true_negatives, false_negatives = 0, 0\n",
    "        true_positives, false_positives = 0, 0\n",
    "\n",
    "        for index, label in enumerate(y):\n",
    "            prediction = self.classify(Integral_Images[index], alphas=self.alphas[:rounds], classifiers=self.classifiers[:rounds], threshold=threshold)\n",
    "\n",
    "            if label == prediction:\n",
    "                if prediction == 1:\n",
    "                    true_positives += 1\n",
    "                else:\n",
    "                    true_negatives += 1\n",
    "            else:\n",
    "                if prediction == 1:\n",
    "                    false_positives += 1\n",
    "                else:\n",
    "                    false_negatives += 1\n",
    "\n",
    "        accuracy = (true_positives + true_negatives) / (true_positives + false_negatives + true_negatives + false_positives)\n",
    "        true_positive_rate = true_positives / (true_positives + false_negatives)\n",
    "        false_positive_rate = false_positives / (false_positives + true_negatives)\n",
    "\n",
    "        if print_details:\n",
    "            print(\"\\nFor Round number {}, we get: \\nthreshold = {},\".format(rounds,threshold))\n",
    "            print (\"Accuracy = {:.4%} ({}/{}),\".format(accuracy,true_positives + true_negatives,true_positives + false_negatives + true_negatives + false_positives))\n",
    "            print (\"False Positive = {:.4%} ({}/{}),\".format(false_positives / (true_positives + false_negatives + true_negatives + false_positives),false_positives,\n",
    "                                                                            true_positives + false_negatives + true_negatives + false_positives,))\n",
    "            print (\"False Negative = {:.4%} ({}/{})\".format(false_negatives / (true_positives + false_negatives + true_negatives + false_positives),\n",
    "                                                                            false_negatives,\n",
    "                                                                            true_positives + false_negatives + true_negatives + false_positives))\n",
    "\n",
    "        return true_positive_rate, false_positive_rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "9n8bBRYIo2O1"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Classifier:\n",
    "    def __init__(self, feature, threshold, polarity):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.polarity = polarity\n",
    "\n",
    "        if self.feature.type_of_feature==(1, 2):\n",
    "          self.feature_name='Vertical_2_rectangle'\n",
    "        if self.feature.type_of_feature==(2,1):\n",
    "          self.feature_name='Horizontal_2_rectangle'\n",
    "        if self.feature.type_of_feature==(3,1):\n",
    "          self.feature_name='Vertical_3_rectangle'\n",
    "\n",
    "        if self.feature.type_of_feature==(1,3):\n",
    "          self.feature_name='Horizontal_3_rectangle'\n",
    "        if self.feature.type_of_feature==(2,2):\n",
    "          self.feature_name='4_rectangles'\n",
    "    \n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Selected classifier details : \\nfeature: {self.feature_name},{self.feature}, \\nthreshold={self.threshold}, \\npolarity={self.polarity}'\n",
    "\n",
    "    def classify(self, integral):\n",
    "        feature_value = self.feature.computeFeature(integral)\n",
    "        return 1 if self.polarity * feature_value < self.polarity * self.threshold else 0\n",
    "\n",
    "    def draw(self, image):\n",
    "        return self.feature.draw(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "aoYW75IG9WWr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "uUyoWpOd9W2o"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Rectangular_Region:\n",
    "    def __init__(self, x, y, width, height, type_of_feature):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.type_of_feature = type_of_feature\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f' Feature details: {self.type_of_feature}, x={self.x}, y={self.y}, width={self.width}, height={self.height}'\n",
    "\n",
    "\n",
    "\n",
    "    def draw(self, image):\n",
    "        image = Image.fromarray(image).convert('RGBA')\n",
    "        drawing = ImageDraw.Draw(image)\n",
    "        if self.type_of_feature == Haar_features['Horizontal_2_rectangle']:\n",
    "            drawing.rectangle(((self.y, self.x), (self.y + self.height, self.x + self.width // 2)), fill = \"white\")\n",
    "            drawing.rectangle(((self.y, self.x + self.width // 2), (self.y + self.height, self.x + self.width)), fill = \"black\")\n",
    "\n",
    "        elif self.type_of_feature == Haar_features['Vertical_2_rectangle']:\n",
    "            drawing.rectangle(((self.y, self.x), (self.y + self.height // 2, self.x + self.width)), fill = \"black\")\n",
    "            drawing.rectangle(((self.y + self.height // 2, self.x), (self.y + self.height, self.x + self.width)), fill = \"white\")\n",
    "\n",
    "        elif self.type_of_feature == Haar_features['Horizontal_3_rectangle']:\n",
    "            drawing.rectangle(((self.y, self.x), (self.y + self.height, self.x + self.width // 3)), fill = \"black\")\n",
    "            drawing.rectangle(((self.y, self.x + self.width // 3), (self.y + self.height, self.x + (2 * self.width) // 3)), fill = \"white\")\n",
    "            drawing.rectangle(((self.y, self.x + (2 * self.width) // 3), (self.y + self.height, self.x + self.width)), fill = \"black\")\n",
    "\n",
    "\n",
    "        elif self.type_of_feature == Haar_features['Vertical_3_rectangle']:\n",
    "            drawing.rectangle(((self.y, self.x), (self.y + self.height // 3, self.x + self.width)), fill = \"black\")\n",
    "            drawing.rectangle(((self.y + self.height // 3, self.x), (self.y + (2 * self.height) // 3, self.x + self.width)), fill = \"white\")\n",
    "            drawing.rectangle(((self.y + (2 * self.height) // 3, self.x), (self.y + self.height, self.x + self.width)), fill = \"black\")\n",
    "\n",
    "        elif self.type_of_feature == Haar_features['4_rectangles']:\n",
    "            drawing.rectangle(((self.y, self.x), (self.y + self.height // 2, self.x + self.width // 2)), fill = \"white\")\n",
    "            drawing.rectangle(((self.y, self.x + self.width // 2), (self.y + self.height // 2, self.x + self.width)), fill = \"black\")\n",
    "            drawing.rectangle(((self.y + self.height // 2, self.x + self.width // 2), (self.y + self.height, self.x + self.width)), fill = \"white\")\n",
    "            drawing.rectangle(((self.y + self.height // 2, self.x), (self.y + self.height, self.x + self.width // 2)), fill = \"black\")\n",
    "\n",
    "        image = image.resize((300, 300))\n",
    "        return image\n",
    "\n",
    "    def computeFeature(self, integral):\n",
    "        if self.type_of_feature == Haar_features['Horizontal_2_rectangle']:\n",
    "            return integral.compute_integral_area([(self.y, self.x),\n",
    "                           (self.y, self.x + self.width // 2),\n",
    "                           (self.y + self.height, self.x + self.width // 2),\n",
    "                           (self.y + self.height, self.x)]) \\\n",
    "                   - integral.compute_integral_area([(self.y, self.x + self.width // 2),\n",
    "                            (self.y, self.x + self.width),\n",
    "                            (self.y + self.height, self.x + self.width),\n",
    "                            (self.y + self.height, self.x + self.width // 2)])\n",
    "\n",
    "        elif self.type_of_feature == Haar_features['Vertical_2_rectangle']:\n",
    "\n",
    "            return - integral.compute_integral_area([(self.y, self.x),\n",
    "                           (self.y, self.x + self.width),\n",
    "                           (self.y + self.height // 2, self.x + self.width),\n",
    "                           (self.y + self.height // 2, self.x)]) \\\n",
    "                   + integral.compute_integral_area([(self.y + self.height // 2, self.x),\n",
    "                            (self.y + self.height // 2, self.x + self.width),\n",
    "                            (self.y + self.height, self.x + self.width),\n",
    "                            (self.y + self.height, self.x)])\n",
    "\n",
    "        elif self.type_of_feature == Haar_features['Horizontal_3_rectangle']:\n",
    "\n",
    "            return - integral.compute_integral_area([(self.y, self.x),\n",
    "                           (self.y, self.x + self.width // 3),\n",
    "                           (self.y + self.height, self.x + self.width // 3),\n",
    "                           (self.y + self.height, self.x)]) \\\n",
    "                   + integral.compute_integral_area( [(self.y, self.x + self.width // 3),\n",
    "                            (self.y, self.x + (2 * self.width) // 3),\n",
    "                            (self.y + self.height, self.x + (2 * self.width) // 3),\n",
    "                            (self.y + self.height, self.x + self.width // 3)]) \\\n",
    "                   - integral.compute_integral_area([(self.y, self.x + (2 * self.width) // 3),\n",
    "                           (self.y, self.x + self.width),\n",
    "                           (self.y + self.height, self.x + self.width),\n",
    "                           (self.y + self.height, self.x + (2 * self.width) // 3)])\n",
    "\n",
    "        elif self.type_of_feature == Haar_features['Vertical_3_rectangle']:\n",
    "\n",
    "            return - integral.compute_integral_area([(self.y, self.x),\n",
    "                           (self.y, self.x + self.width),\n",
    "                           (self.y + self.height // 3, self.x + self.width),\n",
    "                           (self.y + self.height // 3, self.x)]) \\\n",
    "                   + integral.compute_integral_area([(self.y + self.height // 3, self.x),\n",
    "                            (self.y + self.height // 3, self.x + self.width),\n",
    "                            (self.y + (2 * self.height) // 3, self.x + self.width),\n",
    "                            (self.y + (2 * self.height) // 3, self.x)]) \\\n",
    "                   - integral.compute_integral_area([(self.y + (2 * self.height) // 3, self.x),\n",
    "                           (self.y + (2 * self.height) // 3, self.x + self.width),\n",
    "                           (self.y + self.height, self.x + self.width),\n",
    "                           (self.y + self.height, self.x)])\n",
    "\n",
    "        elif self.type_of_feature == Haar_features['4_rectangles']:\n",
    "            return integral.compute_integral_area([(self.y, self.x),\n",
    "                           (self.y, self.x + self.width // 2),\n",
    "                           (self.y + self.height // 2, self.x + self.width // 2),\n",
    "                           (self.y + self.height // 2, self.x)]) \\\n",
    "                   - integral.compute_integral_area([(self.y, self.x + self.width // 2),\n",
    "                            (self.y, self.x + self.width),\n",
    "                            (self.y + self.height // 2, self.x + self.width),\n",
    "                            (self.y + self.height // 2, self.x + self.width // 2)]) \\\n",
    "                   + integral.compute_integral_area([(self.y + self.height // 2, self.x + self.width // 2),\n",
    "                           (self.y + self.height // 2, self.x + self.width),\n",
    "                           (self.y + self.height, self.x + self.width),\n",
    "                           (self.y + self.height, self.x + self.width // 2)]) \\\n",
    "                   - integral.compute_integral_area([(self.y + self.height // 2, self.x),\n",
    "                            (self.y + self.height // 2, self.x + self.width // 2),\n",
    "                            (self.y + self.height, self.x + self.width // 2),\n",
    "                            (self.y + self.height, self.x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "vdSJ2p9kjGq8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 990
    },
    "id": "X7eM9ue29cby",
    "outputId": "49c23b68-22fc-436e-945b-9c4a8f67c79e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Creating the integral images..\n",
      "\n",
      "\n",
      "Creating the integral images done\n",
      "\n",
      "\n",
      "Creating the Haar features\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total features of type Vertical_2_rectangle : 30613\n",
      "\n",
      "\n",
      "Total features of type Horizontal_2_rectangle : 30613\n",
      "\n",
      "\n",
      "Total features of type Vertical_3_rectangle : 19481\n",
      "\n",
      "\n",
      "Total features of type Horizontal_3_rectangle : 19481\n",
      "\n",
      "\n",
      "Total features of type 4_rectangles : 14641\n",
      "\n",
      "\n",
      "Total calculated features: 114829\n",
      "Applying the created Haar features\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 250/114829 [00:06<47:12, 40.45it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-c6fb788846cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnum_rounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mFace_Detector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mViola_Jones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_rounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclassifiers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFace_Detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trained_model.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-5400c6bac0c2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainingData)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIntegral_Images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputeFeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIntegral_Images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-5400c6bac0c2>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIntegral_Images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputeFeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIntegral_Images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-5ddb0438ccaf>\u001b[0m in \u001b[0;36mcomputeFeature\u001b[0;34m(self, integral)\u001b[0m\n\u001b[1;32m     60\u001b[0m                            \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                            \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                            (self.y + self.height // 2, self.x)]) \\\n\u001b[0m\u001b[1;32m     63\u001b[0m                    + integral.compute_integral_area([(self.y + self.height // 2, self.x),\n\u001b[1;32m     64\u001b[0m                             \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "num_rounds = 10\n",
    "Face_Detector = Viola_Jones(num_rounds)\n",
    "classifiers, alphas = Face_Detector.train(trainingData)\n",
    "\n",
    "with open('trained_model.pkl', 'wb') as handler:\n",
    "    pickle.dump(Face_Detector, handler)\n",
    "\n",
    "for index, classifier in enumerate(classifiers):\n",
    "    image = classifier.draw(faces[0])\n",
    "    image.save('results/' + 'round' + str(index + 1) + '.png')\n",
    "\n",
    "# Plot ROC\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "\n",
    "colors = ['r', 'm', 'y' ,'k','w','g', 'b', 'c','coral','darksalmon']\n",
    "rounds = [1,2,3,4,5,6,7,8,9,10]\n",
    "for i in range(len(rounds)):\n",
    "    print(\"\\nEvaluation for rounds: {}\".format(rounds[i]))\n",
    "    true_positive_rates, false_positive_rates = [], []\n",
    "    for threshold in np.arange(0, 1.01, 0.005):\n",
    "        true_positive_rate, false_positive_rate = Face_Detector.evaluate(testData, rounds[i], threshold)\n",
    "        true_positive_rates.append(true_positive_rate)\n",
    "        false_positive_rates.append(false_positive_rate)\n",
    "\n",
    "    plt.plot(false_positive_rates, true_positive_rates, colors[i], label=\"Rounds \" + str(rounds[i]))\n",
    "\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('results/roc.png')\n",
    "\n",
    "print(\"\\nEvaluation metrics (for Training data):\\n\")\n",
    "for i in range(len(rounds)):\n",
    "    Face_Detector.evaluate(trainingData, rounds[i], 0.5, print_details=True)\n",
    "\n",
    "print(\"\\nEvaluation metrics (for test data):\\n\")\n",
    "for i in range(len(rounds)):\n",
    "    Face_Detector.evaluate(testData, rounds[i], 0.5, print_details=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKszH154QaPP"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XXouBwGGBEaI"
   },
   "source": [
    "# Cascade Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "RwMetcqtjJEV"
   },
   "outputs": [],
   "source": [
    "\n",
    "class CascadeClassifier():\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        self.clfs = []\n",
    "\n",
    "    def train(self, trainingData):\n",
    "        faces, nonfaces = [], []\n",
    "        for sample in trainingData:\n",
    "            if sample[1] == 1:\n",
    "                faces.append(sample)\n",
    "            else:\n",
    "                nonfaces.append(sample)\n",
    "       \n",
    "        for rounds in self.layers:\n",
    "            if len(nonfaces) == 0:\n",
    "                print(\"Stopping early. false_positive_rate = 0\")\n",
    "                break\n",
    "\n",
    "            clf = Viola_Jones(rounds = rounds)\n",
    "            clf.train(faces + nonfaces)\n",
    "            self.clfs.append(clf)\n",
    "\n",
    "            X, y = zip(*nonfaces)\n",
    "            Integral_Images = list(map(lambda x: Integral_Image(x), X))\n",
    "        \n",
    "            false_positives = []\n",
    "            for index, sample in enumerate(nonfaces):\n",
    "                if self.classify(Integral_Images[index]) == 1:\n",
    "                    false_positives.append(sample)\n",
    "\n",
    "            print('Layer with %d rounds done' % rounds)\n",
    "            print('Number of non-faces discarded: ', len(nonfaces) - len(false_positives))\n",
    "            nonfaces = false_positives\n",
    "\n",
    "    def classify(self, image):\n",
    "        for clf in self.clfs:\n",
    "            if clf.classify(image) == 0:\n",
    "                return 0\n",
    "\n",
    "        return 1\n",
    "        \n",
    "    def evaluate(self, data):\n",
    "        correct = 0\n",
    "        false_positives = 0\n",
    "        false_negatives = 0\n",
    "\n",
    "        for rounds in self.layers:\n",
    "            curr_data, labels = zip(*data)\n",
    "            Integral_Images = list(map(lambda x: Integral_Image(x), curr_data))\n",
    "        \n",
    "            new_data = []\n",
    "            for index, sample in enumerate(data):\n",
    "                if self.classify(Integral_Images[index]) == 1:\n",
    "                    new_data.append(sample)\n",
    "                else:\n",
    "                    if sample[1] == 1:\n",
    "                        false_negatives += 1\n",
    "                    else:\n",
    "                        correct += 1\n",
    "\n",
    "            data = new_data\n",
    "            print('Layer with %d rounds done' % rounds)\n",
    "\n",
    "        false_positives = len(data)\n",
    "        return (correct, false_positives, false_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3zC_1-yp9n0w",
    "outputId": "6d4b9138-237c-4a65-e236-b648e9213c65"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Creating the integral images..\n",
      "\n",
      "\n",
      "Creating the integral images done\n",
      "\n",
      "\n",
      "Creating the Haar features\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total features of type Vertical_2_rectangle : 30613\n",
      "\n",
      "\n",
      "Total features of type Horizontal_2_rectangle : 30613\n",
      "\n",
      "\n",
      "Total features of type Vertical_3_rectangle : 19481\n",
      "\n",
      "\n",
      "Total features of type Horizontal_3_rectangle : 19481\n",
      "\n",
      "\n",
      "Total features of type 4_rectangles : 14641\n",
      "\n",
      "\n",
      "Total calculated features: 114829\n",
      "Applying the created Haar features\n",
      "\n",
      "\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 114829/114829 [58:38<00:00, 32.64it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Weak Classifier Round number: 1\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11483/11483 [09:31<00:00, 20.08it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected classifier details : \n",
      "feature: Vertical_2_rectangle, Feature details: (1, 2), x=14, y=5, width=1, height=6, \n",
      "threshold=71.0, \n",
      "polarity=-1, \n",
      "error: 2.697079667974937e-05, \n",
      "alpha: 10.520728910609455\n",
      "Layer with 1 rounds done\n",
      "Number of non-faces discarded:  1019\n",
      "\n",
      "\n",
      "Creating the integral images..\n",
      "\n",
      "\n",
      "Creating the integral images done\n",
      "\n",
      "\n",
      "Creating the Haar features\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total features of type Vertical_2_rectangle : 30613\n",
      "\n",
      "\n",
      "Total features of type Horizontal_2_rectangle : 30613\n",
      "\n",
      "\n",
      "Total features of type Vertical_3_rectangle : 19481\n",
      "\n",
      "\n",
      "Total features of type Horizontal_3_rectangle : 19481\n",
      "\n",
      "\n",
      "Total features of type 4_rectangles : 14641\n",
      "\n",
      "\n",
      "Total calculated features: 114829\n",
      "Applying the created Haar features\n",
      "\n",
      "\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 114829/114829 [37:39<00:00, 50.82it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Weak Classifier Round number: 1\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11483/11483 [06:31<00:00, 29.33it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected classifier details : \n",
      "feature: 4_rectangles, Feature details: (2, 2), x=5, y=5, width=8, height=8, \n",
      "threshold=-239.0, \n",
      "polarity=1, \n",
      "error: 4.268116040992132e-05, \n",
      "alpha: 10.061710261217934\n",
      "\n",
      "\n",
      "Training Weak Classifier Round number: 2\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11483/11483 [06:49<00:00, 28.03it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected classifier details : \n",
      "feature: Vertical_3_rectangle, Feature details: (3, 1), x=11, y=4, width=3, height=8, \n",
      "threshold=-1259.0, \n",
      "polarity=1, \n",
      "error: 2.220400597624134e-05, \n",
      "alpha: 10.715215631732297\n",
      "Layer with 2 rounds done\n",
      "Number of non-faces discarded:  86\n",
      "\n",
      "\n",
      "Creating the integral images..\n",
      "\n",
      "\n",
      "Creating the integral images done\n",
      "\n",
      "\n",
      "Creating the Haar features\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total features of type Vertical_2_rectangle : 30613\n",
      "\n",
      "\n",
      "Total features of type Horizontal_2_rectangle : 30613\n",
      "\n",
      "\n",
      "Total features of type Vertical_3_rectangle : 19481\n",
      "\n",
      "\n",
      "Total features of type Horizontal_3_rectangle : 19481\n",
      "\n",
      "\n",
      "Total features of type 4_rectangles : 14641\n",
      "\n",
      "\n",
      "Total calculated features: 114829\n",
      "Applying the created Haar features\n",
      "\n",
      "\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 114829/114829 [35:27<00:00, 53.98it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Weak Classifier Round number: 1\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11483/11483 [05:54<00:00, 32.39it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected classifier details : \n",
      "feature: 4_rectangles, Feature details: (2, 2), x=5, y=5, width=8, height=8, \n",
      "threshold=-224.0, \n",
      "polarity=1, \n",
      "error: 1.3346552477764276e-05, \n",
      "alpha: 11.224239101192412\n",
      "\n",
      "\n",
      "Training Weak Classifier Round number: 2\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11483/11483 [05:57<00:00, 32.15it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected classifier details : \n",
      "feature: Vertical_2_rectangle, Feature details: (1, 2), x=5, y=8, width=2, height=14, \n",
      "threshold=131.0, \n",
      "polarity=1, \n",
      "error: 6.759012335707673e-08, \n",
      "alpha: 16.509803901152083\n",
      "\n",
      "\n",
      "Training Weak Classifier Round number: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11483/11483 [06:16<00:00, 30.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected classifier details : \n",
      "feature: Vertical_3_rectangle, Feature details: (3, 1), x=9, y=9, width=3, height=8, \n",
      "threshold=-479.0, \n",
      "polarity=1, \n",
      "error: 0.0005593846742658095, \n",
      "alpha: 7.488113633119596\n",
      "\n",
      "\n",
      "Training Weak Classifier Round number: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11483/11483 [06:22<00:00, 30.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected classifier details : \n",
      "feature: Vertical_3_rectangle, Feature details: (3, 1), x=9, y=3, width=6, height=14, \n",
      "threshold=-2419.0, \n",
      "polarity=1, \n",
      "error: 0.0005631929163334381, \n",
      "alpha: 7.48132497916346\n",
      "Layer with 4 rounds done\n",
      "Number of non-faces discarded:  25\n",
      "\n",
      "\n",
      "Creating the integral images..\n",
      "\n",
      "\n",
      "Creating the integral images done\n",
      "\n",
      "\n",
      "Creating the Haar features\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total features of type Vertical_2_rectangle : 30613\n",
      "\n",
      "\n",
      "Total features of type Horizontal_2_rectangle : 30613\n",
      "\n",
      "\n",
      "Total features of type Vertical_3_rectangle : 19481\n",
      "\n",
      "\n",
      "Total features of type Horizontal_3_rectangle : 19481\n",
      "\n",
      "\n",
      "Total features of type 4_rectangles : 14641\n",
      "\n",
      "\n",
      "Total calculated features: 114829\n",
      "Applying the created Haar features\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 114829/114829 [36:09<00:00, 52.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Weak Classifier Round number: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11483/11483 [06:09<00:00, 31.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected classifier details : \n",
      "feature: 4_rectangles, Feature details: (2, 2), x=4, y=5, width=8, height=8, \n",
      "threshold=-160.0, \n",
      "polarity=1, \n",
      "error: 3.097893363222609e-06, \n",
      "alpha: 12.684785139831188\n",
      "\n",
      "\n",
      "Training Weak Classifier Round number: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11483/11483 [06:11<00:00, 30.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected classifier details : \n",
      "feature: Vertical_3_rectangle, Feature details: (3, 1), x=10, y=10, width=3, height=6, \n",
      "threshold=-1132.0, \n",
      "polarity=1, \n",
      "error: 4.083052267430955e-08, \n",
      "alpha: 17.013835889609677\n",
      "\n",
      "\n",
      "Training Weak Classifier Round number: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11483/11483 [06:12<00:00, 30.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected classifier details : \n",
      "feature: Vertical_2_rectangle, Feature details: (1, 2), x=5, y=5, width=2, height=8, \n",
      "threshold=74.0, \n",
      "polarity=-1, \n",
      "error: 3.400988735266271e-11, \n",
      "alpha: 24.104369799660514\n",
      "\n",
      "\n",
      "Training Weak Classifier Round number: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11483/11483 [06:10<00:00, 30.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected classifier details : \n",
      "feature: Vertical_2_rectangle, Feature details: (1, 2), x=7, y=8, width=8, height=2, \n",
      "threshold=427.0, \n",
      "polarity=1, \n",
      "error: 0.0003091790878964258, \n",
      "alpha: 8.081280649579844\n",
      "\n",
      "\n",
      "Training Weak Classifier Round number: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11483/11483 [06:12<00:00, 30.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected classifier details : \n",
      "feature: Vertical_2_rectangle, Feature details: (1, 2), x=10, y=6, width=1, height=8, \n",
      "threshold=237.0, \n",
      "polarity=1, \n",
      "error: 0.00031014231804872826, \n",
      "alpha: 8.078169084932979\n",
      "\n",
      "\n",
      "Training Weak Classifier Round number: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11483/11483 [06:11<00:00, 30.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected classifier details : \n",
      "feature: Horizontal_2_rectangle, Feature details: (2, 1), x=8, y=5, width=2, height=1, \n",
      "threshold=41.0, \n",
      "polarity=1, \n",
      "error: 1.6034562505019188e-06, \n",
      "alpha: 13.343347498480341\n",
      "\n",
      "\n",
      "Training Weak Classifier Round number: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11483/11483 [06:11<00:00, 30.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected classifier details : \n",
      "feature: Vertical_3_rectangle, Feature details: (3, 1), x=7, y=11, width=9, height=8, \n",
      "threshold=-1661.0, \n",
      "polarity=1, \n",
      "error: 0.00042080342093634977, \n",
      "alpha: 7.772923874988684\n",
      "\n",
      "\n",
      "Training Weak Classifier Round number: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11483/11483 [06:11<00:00, 30.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected classifier details : \n",
      "feature: Horizontal_2_rectangle, Feature details: (2, 1), x=5, y=7, width=4, height=1, \n",
      "threshold=119.0, \n",
      "polarity=1, \n",
      "error: 0.0003269658993967356, \n",
      "alpha: 8.025327656330898\n",
      "Layer with 8 rounds done\n",
      "Number of non-faces discarded:  8\n",
      "\n",
      "\n",
      "Creating the integral images..\n",
      "\n",
      "\n",
      "Creating the integral images done\n",
      "\n",
      "\n",
      "Creating the Haar features\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total features of type Vertical_2_rectangle : 30613\n",
      "\n",
      "\n",
      "Total features of type Horizontal_2_rectangle : 30613\n",
      "\n",
      "\n",
      "Total features of type Vertical_3_rectangle : 19481\n",
      "\n",
      "\n",
      "Total features of type Horizontal_3_rectangle : 19481\n",
      "\n",
      "\n",
      "Total features of type 4_rectangles : 14641\n",
      "\n",
      "\n",
      "Total calculated features: 114829\n",
      "Applying the created Haar features\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 114829/114829 [36:25<00:00, 52.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Weak Classifier Round number: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11483/11483 [05:52<00:00, 32.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected classifier details : \n",
      "feature: 4_rectangles, Feature details: (2, 2), x=4, y=5, width=8, height=8, \n",
      "threshold=-160.0, \n",
      "polarity=1, \n",
      "error: 3.113324961545013e-06, \n",
      "alpha: 12.679816170076357\n",
      "\n",
      "\n",
      "Training Weak Classifier Round number: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11483/11483 [06:03<00:00, 31.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected classifier details : \n",
      "feature: Vertical_2_rectangle, Feature details: (1, 2), x=10, y=3, width=4, height=4, \n",
      "threshold=-50.0, \n",
      "polarity=1, \n",
      "error: 1.0413335402770562e-08, \n",
      "alpha: 18.38017859140412\n",
      "\n",
      "\n",
      "Training Weak Classifier Round number: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11483/11483 [05:54<00:00, 32.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected classifier details : \n",
      "feature: Vertical_3_rectangle, Feature details: (3, 1), x=0, y=15, width=15, height=2, \n",
      "threshold=130.0, \n",
      "polarity=1, \n",
      "error: 2.054507031500207e-11, \n",
      "alpha: 24.60840004241769\n",
      "\n",
      "\n",
      "Training Weak Classifier Round number: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11483/11483 [05:52<00:00, 32.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected classifier details : \n",
      "feature: Vertical_3_rectangle, Feature details: (3, 1), x=16, y=7, width=6, height=5, \n",
      "threshold=-1511.0, \n",
      "polarity=-1, \n",
      "error: 2.5100587841872087e-14, \n",
      "alpha: 31.315845290141436\n",
      "\n",
      "\n",
      "Training Weak Classifier Round number: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11483/11483 [05:53<00:00, 32.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected classifier details : \n",
      "feature: Vertical_2_rectangle, Feature details: (1, 2), x=5, y=7, width=2, height=4, \n",
      "threshold=28.0, \n",
      "polarity=-1, \n",
      "error: 3.7870840220967523e-07, \n",
      "alpha: 14.786498936592753\n",
      "\n",
      "\n",
      "Training Weak Classifier Round number: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11483/11483 [05:49<00:00, 32.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected classifier details : \n",
      "feature: Horizontal_3_rectangle, Feature details: (1, 3), x=6, y=2, width=5, height=9, \n",
      "threshold=-1326.0, \n",
      "polarity=1, \n",
      "error: 3.8578300504464573e-07, \n",
      "alpha: 14.7679904028656\n",
      "\n",
      "\n",
      "Training Weak Classifier Round number: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11483/11483 [05:49<00:00, 32.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected classifier details : \n",
      "feature: Vertical_2_rectangle, Feature details: (1, 2), x=7, y=8, width=8, height=2, \n",
      "threshold=427.0, \n",
      "polarity=1, \n",
      "error: 0.00031152613122290376, \n",
      "alpha: 8.073715760233595\n",
      "\n",
      "\n",
      "Training Weak Classifier Round number: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11483/11483 [05:52<00:00, 32.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected classifier details : \n",
      "feature: Vertical_2_rectangle, Feature details: (1, 2), x=7, y=9, width=2, height=4, \n",
      "threshold=105.0, \n",
      "polarity=1, \n",
      "error: 9.67513976366241e-07, \n",
      "alpha: 13.848534998774756\n",
      "\n",
      "\n",
      "Training Weak Classifier Round number: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11483/11483 [05:49<00:00, 32.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected classifier details : \n",
      "feature: Vertical_2_rectangle, Feature details: (1, 2), x=16, y=9, width=1, height=2, \n",
      "threshold=59.0, \n",
      "polarity=1, \n",
      "error: 0.00012501858762815646, \n",
      "alpha: 8.986923104288511\n",
      "\n",
      "\n",
      "Training Weak Classifier Round number: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11483/11483 [05:49<00:00, 32.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected classifier details : \n",
      "feature: Vertical_2_rectangle, Feature details: (1, 2), x=7, y=8, width=8, height=2, \n",
      "threshold=427.0, \n",
      "polarity=1, \n",
      "error: 2.3675570521261144e-06, \n",
      "alpha: 12.95364954656932\n",
      "Layer with 10 rounds done\n",
      "Number of non-faces discarded:  6\n",
      "Training the classifier done!\n",
      "\n",
      "****************\n",
      "Evaluating the test data now...\n",
      "Layer with 1 rounds done\n",
      "Layer with 2 rounds done\n",
      "Layer with 4 rounds done\n",
      "Layer with 8 rounds done\n",
      "Layer with 10 rounds done\n",
      "\n",
      "****************\n",
      "Cascade Classifier on Test\n",
      "Training accuracy: 0.41 (284/686)\n",
      "False positive: 0.51 (349/686)\n",
      "False negative: 0.08 (53/686)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cascadeDetector = CascadeClassifier([1, 2, 4, 8, 10])\n",
    "cascadeDetector.train(trainingData)\n",
    "print(\"Training the classifier done!\")\n",
    "\n",
    "# Save cascade classifier\n",
    "with open('cascade.pkl', 'wb') as handler:\n",
    "    pickle.dump(cascadeDetector, handler)\n",
    "\n",
    "print('\\n****************')\n",
    "print(\"Evaluating the test data now...\")\n",
    "correct, fp, fn = cascadeDetector.evaluate(testData)\n",
    "\n",
    "f = len(testfaces)\n",
    "nf = len(testnonfaces)\n",
    "print('\\n****************')\n",
    "print('Cascade Classifier on Test')\n",
    "print('Training accuracy: %.2f (%d/%d)' % (correct / (f + nf), correct, f + nf))\n",
    "print('False positive: %.2f (%d/%d)' % (fp / (f + nf), fp, (f + nf)))\n",
    "print('False negative: %.2f (%d/%d)\\n' % (fn / (f + nf), fn, (f + nf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "k69DrachoGM7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Face_Detection_PR_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
